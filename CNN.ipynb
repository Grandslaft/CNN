{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from functions.layers import Conv, MaxPool, FCL\n",
    "from functions.model import Main_Model\n",
    "from functions.plot_graph import show_graph, show_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = pd.read_csv(\"train.csv\").sample(frac=.05).to_numpy()\n",
    "# X = idx2numpy.convert_from_file('D:\\\\Programming\\\\Projects\\\\data_sets\\\\num_mnist_X.idx3-ubyte').astype('float32')\n",
    "# Y = idx2numpy.convert_from_file('D:\\\\Programming\\\\Projects\\\\data_sets\\\\num_mnist_Y.idx1-ubyte')\n",
    "\n",
    "# X = X.reshape(-1, 1, 28, 28)\n",
    "\n",
    "# # minmax\n",
    "# X = (X - np.min(X, axis=(2,3), keepdims=True)) / (np.max(X, axis=(2,3), keepdims=True) - np.min(X, axis=(2,3), keepdims=True))\n",
    "\n",
    "# # Z-score\n",
    "# # X = (X - np.mean(X, axis=(2,3), keepdims=True)) / np.var(X, axis=(2,3), keepdims=True)\n",
    "\n",
    "# Y_onehot = OneHotEncoder().fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y_onehot, test_size=0.05, random_state=101)\n",
    "\n",
    "# percent = 0.1\n",
    "# sample = np.random.choice([True, False], size=X_test.shape[0], p=[percent, 1-percent])\n",
    "# X_val = X_test[sample]\n",
    "# y_val = y_test[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All possible categories\n",
    "labels = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot',\n",
    "}\n",
    "\n",
    "# import train data\n",
    "X_train = idx2numpy.convert_from_file('.\\Fashion_MNIST\\TrainX').astype('float32')\n",
    "y_train = idx2numpy.convert_from_file('.\\Fashion_MNIST\\TrainY').reshape(-1, 1)\n",
    "\n",
    "# import test data\n",
    "X_test = idx2numpy.convert_from_file('.\\Fashion_MNIST\\TestX').astype('float32')\n",
    "y_test = idx2numpy.convert_from_file('.\\Fashion_MNIST\\TestY').reshape(-1, 1)\n",
    "\n",
    "# reshape to needed format\n",
    "X_train, X_test = X_train.reshape(-1, 1, 28, 28), X_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "# minmax normalization\n",
    "X_max, X_min = np.max(X_train), np.min(X_train)\n",
    "X_train = (X_train - X_min) / (X_max - X_min)\n",
    "X_test = (X_test - X_min) / (X_max - X_min)\n",
    "\n",
    "# shuffle train data\n",
    "shuffled_indices = np.random.permutation(len(X_train))\n",
    "X_train = X_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]\n",
    "\n",
    "# extracting unique categories with indices\n",
    "unique_vals, indices = np.unique(y_train, return_index=True)\n",
    "\n",
    "# Z-score normalization\n",
    "# X_mean, X_std = np.mean(X_train), np.std(X_train), \n",
    "# X_train = (X_train - X_mean)/X_std\n",
    "# X_test = (X_test - X_mean)/X_std\n",
    "\n",
    "# PDF of the train data\n",
    "sns.countplot(x=y_train.flatten())\n",
    "plt.xticks(ticks=np.arange(10), labels=list(labels.values()), rotation=45)\n",
    "\n",
    "# One-Hot encoding\n",
    "OneHot = OneHotEncoder(sparse_output=False).fit(y_train)\n",
    "y_train_OH = OneHot.transform(y_train)\n",
    "y_test_OH = OneHot.transform(y_test)\n",
    "\n",
    "# extract some data for validation\n",
    "percent = 0.01\n",
    "sample = np.random.choice([True, False], size=X_test.shape[0], p=[percent, 1-percent])\n",
    "X_val = X_test[sample]\n",
    "y_val = y_test_OH[sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of each type of clothe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,5)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    axs[np.unravel_index(i, shape=(2,5))].imshow(X_train[idx, 0], cmap='Greys')\n",
    "    axs[np.unravel_index(i, shape=(2,5))].title.set_text(labels.get(y_train[idx, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating layers\n",
    "layers = [\n",
    "    Conv(num_filters=5, size=5, stride=1, activation='relu'),\n",
    "    Conv(num_filters=10, size=5, stride=1, activation='relu'), \n",
    "    MaxPool(size=2, stride=2),\n",
    "    FCL(n_inputs=1000, n_neurons=300, activation='elu'),\n",
    "    FCL(n_inputs=300, n_neurons=10, activation='softmax'),\n",
    "]\n",
    "\n",
    "# create CNN model\n",
    "CNN = Main_Model(layers)\n",
    "\n",
    "# set early stop params\n",
    "CNN.EarlyStop(monitor = \"val_accuracy\", min_delta = 5e-3, min_monitor=0.65, patience = 3, restore_best_layers=True)\n",
    "\n",
    "# start training\n",
    "val_step = 50\n",
    "step = 10\n",
    "CNN.train(X_train, y_train_OH, X_val, y_val, epochs=1, learning_rate=0.01, lr_decay=0.001, step=step, val_step=val_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN.restore_best_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_axis = list( range(len(CNN.history['accuracy'][0]) ) )\n",
    "show_graph(X_axis, CNN.history['accuracy'], CNN.history['val_accuracy'], 'accuracy', 'val_accuracy', 2, 0.1, 'avg accuracy per image pack', 'image pack', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(X_axis, CNN.history['loss'], CNN.history['val_loss'], 'loss', 'val_loss', 18, 1, 'loss per image pack', 'image pack', 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=y_test.flatten())\n",
    "plt.xticks(ticks=np.arange(10), labels=list(labels.values()), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_predicted = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_test_class = X_test[:100][y_test[:100].flatten() == i]\n",
    "    predictions = CNN.predict(X_test_class)\n",
    "    correctly_predicted.append(np.sum(predictions == i))\n",
    "    accuracies.append(correctly_predicted[-1] / len(predictions))\n",
    "    \n",
    "correctly_predicted, accuracies = np.array(correctly_predicted), np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bar(list(labels.values()), accuracies, 'Accuracy on each clothe type, %', 'Clothe', 'Accuracy, [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(accuracies)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create layers\n",
    "layers = [\n",
    "    FCL(n_inputs=784, n_neurons=64, activation='relu'),\n",
    "    FCL(n_inputs=64, n_neurons=32, activation='relu'),\n",
    "    FCL(n_inputs=32, n_neurons=10, activation='softmax'),\n",
    "]\n",
    "\n",
    "# create model\n",
    "MLP = Main_Model(layers)\n",
    "\n",
    "# set early stop params\n",
    "MLP.EarlyStop(monitor = \"val_accuracy\", min_delta = 1e-3, min_monitor=0.8, patience = 5, restore_best_layers=True)\n",
    "\n",
    "# training\n",
    "val_step = 10000\n",
    "step = 10\n",
    "MLP.train(X_train, y_train_OH, X_val, y_val, epochs=5, learning_rate=0.01, lr_decay=0.0001, step=step, val_step=val_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP.restore_best_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_axis = list( range( len(MLP.history['accuracy'][0]) ) )\n",
    "\n",
    "show_graph(X_axis, MLP.history['accuracy'], MLP.history['val_accuracy'], 'accuracy', 'val_accuracy', 45, 0.3, 'avg accuracy per image pack', 'image pack', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(X_axis, MLP.history['loss'], MLP.history['val_loss'], 'loss', 'val_loss', 375, 5, 'loss per image pack', 'image pack', 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = MLP.predict(X_test)\n",
    "# accuracy_score(np.argmax(y_test[:1000], 1), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_predicted = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(10):\n",
    "    X_test_class = X_test[y_test.flatten() == i]\n",
    "    predictions = MLP.predict(X_test_class)\n",
    "    correctly_predicted.append(np.sum(predictions == i))\n",
    "    accuracies.append(correctly_predicted[-1] / len(predictions))\n",
    "    \n",
    "correctly_predicted, accuracies = np.array(correctly_predicted), np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bar(list(labels.values()), accuracies, 'Accuracy on each clothe type, %', 'Clothe', 'Accuracy, [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(accuracies)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(-1, 28, 28, 1), X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(5, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=SGD(\n",
    "        learning_rate=0.01), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "training_history = model.fit(\n",
    "    X_train, y_train_OH, \n",
    "    validation_data=(X_val, y_val), \n",
    "    epochs=1, batch_size=1\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_OH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "university",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import idx2numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import PIL\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time of {func.__name__}: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class for the Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        if name == 'sigmoid':\n",
    "            self.function = self.exponent\n",
    "            self.derivative = self.exponent_der\n",
    "        elif name == 'tanh':\n",
    "            self.function = lambda x: np.tanh(x)\n",
    "            self.derivative = lambda x: 1 - np.square(np.tanh(x))\n",
    "        elif name == 'softmax':\n",
    "            self.function = self.softmax\n",
    "            self.derivative = self.softmax_der\n",
    "        elif name == 'relu':\n",
    "            self.function = lambda x: np.maximum(0, x)\n",
    "            self.derivative = lambda x: x > 0\n",
    "        \n",
    "    def exponent(self, x):\n",
    "        shift_x = x - np.max(x)\n",
    "        return 1/(1 + np.exp(-shift_x))\n",
    "    \n",
    "    def exponent_der(self, x):\n",
    "        exps = self.exponent(x)\n",
    "        return exps * (1 - exps)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        shift_x = x - np.max(x)\n",
    "        exps = np.exp(shift_x)\n",
    "        return exps/np.sum(exps)\n",
    "    \n",
    "    def softmax_der(self, x):\n",
    "        array = self.softmax(x).reshape(-1,1)\n",
    "        return np.diagflat(array) - np.dot(array, array.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "\n",
    "    def __init__(self, num_filters = 3, size = 3, stride = 1, activation = 'relu'):\n",
    "        self.next_layer = None\n",
    "        self.num_filters = num_filters\n",
    "        self.size = size\n",
    "        self.stride = stride\n",
    "        self.activation = Activation(activation)\n",
    "\n",
    "        self.filters = np.random.randn(num_filters, size, size) / 10\n",
    "    \n",
    "    def add_layer(self, child):\n",
    "        self.next_layer = child\n",
    "        return self\n",
    "    \n",
    "    def iterate_regions(self, h, w):\n",
    "\n",
    "        for i in range(h - (self.dim_f - 1)):\n",
    "            for j in range(w - (self.dim_f - 1)):\n",
    "                im_region = np.array([\n",
    "                    np.arange(i, i + self.dim_f), \n",
    "                    np.arange(j, j + self.dim_f)\n",
    "                ])\n",
    "                yield im_region, i, j\n",
    "    # @calculate_execution_time            \n",
    "    def forward(self, image):\n",
    "        self.last_input = image\n",
    "        input_dimension = image.shape[1]\n",
    "        output_dimension = int((input_dimension - self.size) / self.stride) + 1\n",
    "        out = np.zeros((self.filters.shape[0], output_dimension, output_dimension))\n",
    "        \n",
    "        for f in range(self.num_filters):\n",
    "            current_y = out_y = 0\n",
    "            \n",
    "            while current_y + self.size <= input_dimension:\n",
    "                current_x = out_x = 0\n",
    "                \n",
    "                while current_x + self.size <= input_dimension:\n",
    "                    patch = image[:, current_y:current_y + self.size, current_x:current_x + self.size]\n",
    "                    out[f, out_y, out_x] = np.sum(self.filters[f] * patch)\n",
    "                    current_x += self.stride\n",
    "                    out_x += 1\n",
    "                    \n",
    "                current_y += self.stride\n",
    "                out_y += 1\n",
    "                \n",
    "        self.last_output = out\n",
    "        if self.activation:\n",
    "            out = self.activation.function(out)\n",
    "        return out\n",
    "    # @calculate_execution_time\n",
    "    def backward(self, out_prev, lr):\n",
    "        input_dimension = self.last_input.shape[1]\n",
    "        \n",
    "        if self.activation:\n",
    "            out_prev = out_prev * self.activation.derivative(self.last_output)\n",
    "        \n",
    "        out_next = np.zeros(self.last_input.shape)\n",
    "        dfilt = np.zeros(self.filters.shape)\n",
    "        \n",
    "        for f in range(self.filters.shape[0]):\n",
    "            current_y = out_y = 0\n",
    "            \n",
    "            while current_y + self.size <= input_dimension:\n",
    "                current_x = out_x = 0\n",
    "                \n",
    "                while current_x + self.size <= input_dimension:\n",
    "                    patch = self.last_input[:, current_y:current_y + self.size, current_x:current_x + self.size]\n",
    "                    dfilt[f] += np.sum(out_prev[f, out_y, out_x] * patch, axis=0)\n",
    "                    out_next[:, current_y:current_y + self.size, current_x:current_x + self.size] += out_prev[f, out_y, out_x] * self.filters[f]\n",
    "                    current_x += self.stride\n",
    "                    out_x += 1\n",
    "                    \n",
    "                current_y += self.stride\n",
    "                out_y += 1\n",
    "                \n",
    "        self.filters -= lr * dfilt\n",
    "        return out_next\n",
    "    \n",
    "    # def forward(self, input):\n",
    "    #     self.last_input = input\n",
    "    #     _, h, w = input.shape\n",
    "    #     output = np.zeros((self.num_filters, h - (self.dim_f - 1), w - (self.dim_f - 1)))\n",
    "        \n",
    "        \n",
    "    #     for im_region, i, j in self.iterate_regions(h, w):\n",
    "    #         for f_i, filters in enumerate(self.filters):\n",
    "    #             output[:, i, j] = np.sum(np.multiply(input[:, im_region[0][:, np.newaxis], im_region[1]], filters))\n",
    "        \n",
    "    #     return self.activation.function(output)\n",
    "    \n",
    "    # def backward(self, out_prev, learning_rate):\n",
    "    #     out_prev = np.clip(out_prev, -1e+10, 1e+10)\n",
    "    #     d_L_d_filters = np.zeros_like(self.filters)\n",
    "    #     out_next = np.zeros_like(self.last_input)\n",
    "        \n",
    "    #     nf, h, w = out_prev.shape\n",
    "\n",
    "    #     for im_region, i, j in self.iterate_regions(h, w):\n",
    "    #         for f in range(nf):\n",
    "    #             d_L_d_filters[f] += np.multiply(out_prev[f, i, j], out_prev[f, im_region[0][:, np.newaxis], im_region[1]])\n",
    "    #             out_next[:, i, j] += np.sum(np.multiply(out_prev[f, im_region[0][:, np.newaxis], im_region[1]], self.filters[f]))\n",
    "    #     # Update filters\n",
    "    #     self.filters -= learning_rate * d_L_d_filters\n",
    "    #     return out_next\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool:\n",
    "    \n",
    "    def __init__(self, size = 2, stride = 2, activation = 'relu'):\n",
    "        self.next_layer = None\n",
    "        self.stride = stride\n",
    "        self.size = size\n",
    "        self.activation = Activation(activation)\n",
    "    \n",
    "    def add_layer(self, child):\n",
    "        self.next_layer = child\n",
    "        return self\n",
    "    \n",
    "    # def iterate_regions(self, image):\n",
    "    #     _, h, w = image.shape\n",
    "    #     new_h = h // 2\n",
    "    #     new_w = w // 2\n",
    "\n",
    "    #     for i in range(new_h):\n",
    "    #         for j in range(new_w):\n",
    "    #             im_region = image[:, (i * 2):(i * 2 + (self.dim_f - 1)), (j * 2):(j * 2 + (self.dim_f - 1))]\n",
    "    #             yield im_region, i, j\n",
    "    # @calculate_execution_time            \n",
    "    def forward(self, image):\n",
    "        self.last_input = image\n",
    "        \n",
    "        nfilt, h_prev, w_prev = image.shape\n",
    "        h = int((h_prev - self.size) / self.stride) + 1\n",
    "        w = int((w_prev - self.size) / self.stride) + 1\n",
    "        \n",
    "        downscaled = np.zeros((nfilt, h, w))\n",
    "        \n",
    "        for i in range(nfilt):\n",
    "            curr_y = out_y = 0\n",
    "            \n",
    "            while curr_y + self.size <= h_prev:\n",
    "                curr_x = out_x = 0\n",
    "                \n",
    "                while curr_x + self.size <= w_prev:\n",
    "                    patch = image[i, curr_y:curr_y + self.size, curr_x:curr_x + self.size]\n",
    "                    downscaled[i, out_y, out_x] = np.max(patch)\n",
    "                    curr_x += self.stride\n",
    "                    out_x += 1\n",
    "                    \n",
    "                curr_y += self.stride\n",
    "                out_y += 1\n",
    "                \n",
    "        return downscaled\n",
    "    # @calculate_execution_time\n",
    "    def backward(self, out_prev, learning_rate):\n",
    "        # out_prev = np.clip(out_prev, -1e+10, 1e+10)\n",
    "        out_next = np.zeros(self.last_input.shape)\n",
    "\n",
    "        nfilt, shape, _ = self.last_input.shape\n",
    "        \n",
    "        for c in range(nfilt):\n",
    "            current_y = out_y = 0\n",
    "            while current_y + self.size <= shape:\n",
    "                current_x = out_x = 0\n",
    "                while current_x + self.size <= shape:\n",
    "                    patch = self.last_input[c, current_y:current_y + self.size, current_x:current_x + self.size]\n",
    "                    (x, y) = np.unravel_index(np.nanargmax(patch), patch.shape)\n",
    "                    out_next[c, current_y + x, current_x + y] += out_prev[c, out_y, out_x]\n",
    "                    current_x += self.stride\n",
    "                    out_x += 1\n",
    "                current_y += self.stride\n",
    "                out_y += 1\n",
    "        return out_next\n",
    "\n",
    "    # def forward(self, input):\n",
    "    #     self.last_input = input\n",
    "        \n",
    "    #     num_filters, h, w = input.shape\n",
    "    #     output = np.zeros((num_filters, h // self.dim_f, w // self.dim_f))\n",
    "        \n",
    "    #     if self.type == 'max':\n",
    "    #         for im_region, i, j in self.iterate_regions(input):\n",
    "    #             output[:, i, j] = np.amax(im_region, axis=(1, 2))\n",
    "        \n",
    "    #     return self.activation.function(output)\n",
    "\n",
    "    # def backward(self, out_prev, learning_rate):\n",
    "    #     out_prev = np.clip(out_prev, -1e+10, 1e+10)\n",
    "    #     out_next = np.zeros(self.last_input.shape)\n",
    "\n",
    "    #     for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "    #         f, h, w = im_region.shape\n",
    "    #         amax = np.amax(im_region, axis=(1, 2))\n",
    "    #         for f2 in range(f):\n",
    "    #             for i2 in range(h):\n",
    "    #                 for j2 in range(w):\n",
    "    #                     # If this pixel was the max value, copy the gradient to it.\n",
    "    #                     if im_region[f2, i2, j2] == amax[f2]:\n",
    "    #                         out_next[f2, i * 2 + i2, j * 2 + j2] = out_prev[f2, i, j]\n",
    "\n",
    "    #         return out_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self, n_inputs, n_neurons, activation):\n",
    "        self.next_layer = None\n",
    "        self.weights = np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.random.randn(n_neurons)\n",
    "        self.activation = Activation(activation)\n",
    "\n",
    "    def add_layer(self, child):\n",
    "        self.next_layer = child\n",
    "        return self\n",
    "    # @calculate_execution_time\n",
    "    def forward(self, input):\n",
    "        self.last_input_shape = input.shape\n",
    "        input = input.flatten()\n",
    "        output = np.dot(input, self.weights) + self.biases\n",
    "        self.last_input = input\n",
    "        self.last_output = output\n",
    "        return self.activation.function(output)\n",
    "    # @calculate_execution_time\n",
    "    def backward(self, input, learning_rate):\n",
    "        if self.next_layer is None:\n",
    "            dW = input[:, np.newaxis]\n",
    "        else:\n",
    "            dW = input[:, np.newaxis] * self.activation.derivative(self.last_output)[:, np.newaxis]\n",
    "        dW = (dW * self.last_input[np.newaxis, :]).T\n",
    "        db = np.copy(input)\n",
    "        dout = self.weights @ input\n",
    "        self.weights -= learning_rate * dW\n",
    "        self.biases -= learning_rate * db\n",
    "        return dout.reshape(self.last_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        if len(layers) < 2:\n",
    "            raise ValueError(\"Not enough layers. Should be at least 2\")\n",
    "        \n",
    "        self.layers = [layers[0]]\n",
    "        \n",
    "        for layer in layers[1:]:\n",
    "            self.layers[-1].add_layer(layer)\n",
    "            if layer is not None and layer not in self.layers:\n",
    "                self.layers.append(layer)\n",
    "        \n",
    "        self.early_stop = None\n",
    "        \n",
    "    # @calculate_execution_time\n",
    "    def forward(self, image):\n",
    "        for layer in self.layers:\n",
    "            image = layer.forward(image)\n",
    "        return image\n",
    "    # @calculate_execution_time\n",
    "    def backward(self, gradient, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(gradient, learning_rate)\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=10, learning_rate=0.1, lr_decay=0, X_val=None, y_val=None):\n",
    "        losses = []\n",
    "        accuracy = []\n",
    "        \n",
    "        learning_rate_0 = learning_rate\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # self.history['accuracy'][epoch] = []\n",
    "            # self.history['loss'][epoch] = []\n",
    "            for i in range(X_train.shape[0]):\n",
    "                image = X_train[i]\n",
    "                onehotlabel = y_train[i]\n",
    "                label = np.argmax(onehotlabel)\n",
    "                \n",
    "                output = self.forward(image)\n",
    "                \n",
    "                current_accuracy = output[label]\n",
    "                current_loss = -np.sum(y_train[i] * np.log(output))\n",
    "                \n",
    "                accuracy.append(current_accuracy)\n",
    "                losses.append(current_loss)\n",
    "                \n",
    "                gradient = np.copy(output) - onehotlabel\n",
    "                self.backward(gradient, learning_rate)\n",
    "                \n",
    "                # learning_rate = (lr_decay**i)*learning_rate_0\n",
    "                \n",
    "                # if self.early_stop is not None:\n",
    "                #     if self.EarlyStopping(epoch, i, current_accuracy, current_loss):\n",
    "                #         self.output = np.array(output)\n",
    "                #         return 0\n",
    "                \n",
    "                if i % 100 == 0:\n",
    "                    print(f'image: {i + 1:}')\n",
    "                    print(f'accuracy: {np.mean(accuracy):.4f}, loss: {np.mean(losses):.4f}')\n",
    "                    losses = []\n",
    "                    accuracy = []\n",
    "                    if X_val is not None and y_val is not None:\n",
    "                        val_acc, val_loss = self.val_pred(X_val, y_val)\n",
    "                        print(f'val_accuracy: {val_acc:.4f}, val_loss: {val_loss:.4f}')\n",
    "                    print('===========')\n",
    "        \n",
    "        self.output = np.array(output)\n",
    "        \n",
    "    \n",
    "    def val_pred(self, X_val, y_val):\n",
    "        accuracy_list = []\n",
    "        loss_list = []\n",
    "        for i, image in enumerate(X_val):\n",
    "            label = np.argmax(y_val[i])\n",
    "            \n",
    "            output = self.forward(image)\n",
    "            \n",
    "            accuracy = output[label]\n",
    "            loss = -np.sum(y_val[i] * np.log(output, out=np.zeros_like(output), where=(output!=0)))\n",
    "            \n",
    "            accuracy_list.append(accuracy)\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "        return np.mean(accuracy_list), np.mean(loss_list)\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([np.argmax(self.forward(x), 0) for x in X])\n",
    "        \n",
    "    def EarlyStop(self, monitor=\"accuracy\", min_delta=.1, patience=3):\n",
    "        self.early_stop = {\n",
    "            \"monitor\": monitor, \n",
    "            \"min_delta\": min_delta, \n",
    "            \"patience\": patience, \n",
    "        }\n",
    "        \n",
    "        self.history = {\n",
    "            \"accuracy\": {},\n",
    "            \"loss\" : {},\n",
    "            \"global_max_index\": 0,\n",
    "        }\n",
    "    \n",
    "    def EarlyStopping(self, epoch, im_i, accuracy, loss):\n",
    "        self.history['accuracy'][epoch].append(accuracy)\n",
    "        self.history['loss'][epoch].append(loss)\n",
    "        \n",
    "        if epoch > self.early_stop['patience']:\n",
    "            if self.history[self.early_stop['monitor']][epoch][-1] > self.history[self.early_stop['monitor']][self.history['global_max_index'][0]][self.history['global_max_index'][1]]:\n",
    "                self.history['global_max_index'] = (epoch, im_i)\n",
    "            \n",
    "            min_local_accuracy = min(self.history[self.early_stop['monitor']][epoch][-self.early_stop['patience']:])\n",
    "            difference = abs(min_local_accuracy - self.history[self.early_stop['monitor']][self.history['global_max_index'][0]][self.history['global_max_index'][1]])\n",
    "            \n",
    "            if difference < self.early_stop['min_delta']:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data = pd.read_csv(\"train.csv\").sample(frac=.05).to_numpy()\n",
    "# X = idx2numpy.convert_from_file('D:\\\\Programming\\\\Projects\\\\data_sets\\\\t10k-images.idx3-ubyte').astype('float32')\n",
    "# Y = idx2numpy.convert_from_file('D:\\\\Programming\\\\Projects\\\\data_sets\\\\t10k-labels.idx1-ubyte')\n",
    "\n",
    "# X = X.reshape(-1, 1, 28, 28)\n",
    "\n",
    "# # minmax\n",
    "# # X = (X - np.min(X, axis=(2,3), keepdims=True)) / (np.max(X, axis=(2,3), keepdims=True) - np.min(X, axis=(2,3), keepdims=True))\n",
    "\n",
    "# # Z-score\n",
    "# X = (X - np.mean(X, axis=(2,3), keepdims=True)) / np.var(X, axis=(2,3), keepdims=True)\n",
    "\n",
    "# Y_onehot = OneHotEncoder().fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y_onehot, test_size=0.01, random_state=2077)\n",
    "\n",
    "# # percent = 0.1\n",
    "# # sample = np.random.choice([True, False], size=X_test.shape[0], p=[percent, 1-percent])\n",
    "# # X_val = X_test[sample]\n",
    "# # y_val = np.argmax(y_test[sample], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "X = idx2numpy.convert_from_file('D:\\\\Programming\\\\Projects\\\\data_sets\\\\t10k-images.idx3-ubyte').astype('float32')\n",
    "Y = idx2numpy.convert_from_file('D:\\\\Programming\\\\Projects\\\\data_sets\\\\t10k-labels.idx1-ubyte')\n",
    "\n",
    "X= X.reshape(-1, 1, 28, 28)\n",
    "X = (X - np.mean(X, axis=(2,3), keepdims=True)) / np.var(X, axis=(2,3), keepdims=True)\n",
    "Y = (Y[:, None] == np.unique(Y)).astype(int)\n",
    "\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "\n",
    "X_train = X[:5000]\n",
    "y_train = Y[:5000]\n",
    "X_val = X[5000:5100]\n",
    "y_val = Y[5000:5100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "accuracy: 0.0110, loss: 4.5061\n",
      "val_accuracy: 0.0461, val_loss: 18.9160\n",
      "===========\n",
      "image: 101\n",
      "accuracy: 0.0801, loss: 6.5480\n",
      "val_accuracy: 0.1023, val_loss: 2.4863\n",
      "===========\n",
      "image: 201\n",
      "accuracy: 0.0991, loss: 2.7980\n",
      "val_accuracy: 0.1087, val_loss: 2.4873\n",
      "===========\n",
      "image: 301\n",
      "accuracy: 0.1472, loss: 2.8285\n",
      "val_accuracy: 0.1245, val_loss: 2.6380\n",
      "===========\n",
      "image: 401\n",
      "accuracy: 0.0888, loss: 2.7925\n",
      "val_accuracy: 0.0961, val_loss: 2.8469\n",
      "===========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m CNN_model \u001b[38;5;241m=\u001b[39m CNN(layers)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# CNN_model.EarlyStop(monitor = \"loss\", min_delta = 1e-4, patience = 5)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mCNN_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# CNN_model.train(X_train, y_train, X_val, y_val, epochs=1, learning_rate=1e-2, lr_decay=0, verbose=True)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 40\u001b[0m, in \u001b[0;36mCNN.train\u001b[1;34m(self, X_train, y_train, epochs, learning_rate, lr_decay, X_val, y_val)\u001b[0m\n\u001b[0;32m     37\u001b[0m onehotlabel \u001b[38;5;241m=\u001b[39m y_train[i]\n\u001b[0;32m     38\u001b[0m label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(onehotlabel)\n\u001b[1;32m---> 40\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m current_accuracy \u001b[38;5;241m=\u001b[39m output[label]\n\u001b[0;32m     43\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(y_train[i] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(output))\n",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 19\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "Cell \u001b[1;32mIn[14], line 30\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     28\u001b[0m input_dimension \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     29\u001b[0m output_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((input_dimension \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 30\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], output_dimension, output_dimension))\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_filters):\n\u001b[0;32m     33\u001b[0m     current_y \u001b[38;5;241m=\u001b[39m out_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Conv(num_filters=8, size=5, stride=1),\n",
    "    Conv(num_filters=7, size=5, stride=1), \n",
    "    Pool(size=2, stride=2),\n",
    "    Dense(n_inputs=700, n_neurons=128, activation='relu'),\n",
    "    Dense(n_inputs=128, n_neurons=10, activation='softmax'),\n",
    "]\n",
    "\n",
    "CNN_model = CNN(layers)\n",
    "\n",
    "# CNN_model.EarlyStop(monitor = \"loss\", min_delta = 1e-4, patience = 5)\n",
    "\n",
    "CNN_model.train(X_train, y_train, epochs=1, learning_rate=0.01, lr_decay=0., X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CNN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_test, 1), predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "university",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
